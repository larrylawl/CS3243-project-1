% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{capt-of}
\usetikzlibrary{matrix}
\usepackage[toc,page]{appendix}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{An Evaluation of Uninformed and Informed Search Algorithms on the k-puzzle Problem\thanks{Supported by Prof Yair Zick and Prof Daren Ler.}}
%
\titlerunning{Evaluation of Search Algos on k-puzzle}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Dalis Chan \textit{(A0187451Y)} \and
Johanna \textit{(A0187536R)} \and
Sean Low Chen Yi \textit{(A0183743Y)} \and 
Law Ann Liat, Larry \textit{(A0189883A)}}

\authorrunning{D.C., J, S.L., L.L.}
%
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%

\institute{National University of Singapore \\
%TODO: change to diff colours
Repository Link \href{https://github.com/larrylawl/CS3243-project-1}{here}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
K-puzzle is often used as test problems for new search algorithms in artificial intelligence ~\cite[p71]{stuart_russell_artifical_2010}. This paper evaluates the use of iterative deepening search (IDS) and \( A^* \) search. 
Since \( A^* \) search uses heuristic functions to guide its search, this paper also evalutes the heuristic functions Euclidean Distance, Manhattan Distance, and linear conflict.
\end{abstract}
%
%
%
\section{Problem Specification}
\begin{enumerate}
    \item \textbf{State:} For \( k \in \{3, 4, 5\} \),  a \( k \times k \) matrix \( M \) with each entry \( m_{i, j} \) being a unique integer from \( \{0, 1, \cdots, 8 \} \) where 0 represents the blank tile.
    \item \textbf{Initial State:} Puzzle can start in any state \textit{s}.
    \item \textbf{Actions or \textit{Actions(s)}:} Let \( m_{k, l} \in M \) denote the blank tile and \( m_{i, j} \in M \) denote the tile \textbf{adjacent} to the blank tile \( m_{k, l} \).
    Actions are movements of the adjacent tile \( m_{i, j} \) towards the blank tile \( m_{k, l} \). For example, the action \textit{Left} moves the adjacent tile \( m_{k, l+1} \in M \) to the blank tile \( m_{k, l} \).
    \item \textbf{Transition Model or \textit{Result(s,a)}:} \( Result(s, a) \) swaps the pair of tiles specified in action \( a \) in the current state \textit{s} and returns this new state \textit{s'}.
    \item \textbf{Goal State:} 
    \[
    M_{goal}= \begin{bmatrix}
        1 & 2 & \cdots & k \\
        k+1 & k+2 & \cdots & 2k \\
        \vdots & \vdots & \vdots \\
        k^2 - k + 1 & k^2 - k & \cdots & 0
        \end{bmatrix}
    \]
    \item \textbf{Path Cost:} Every step cost \textit{c(s, a, s') = 1}, and the path cost is the summation of the step costs from the initial state to the goal state.
\end{enumerate}

\section{Technical Analysis of the Selected Algorithms and Heuristics}
\label{section2}
\subsection{Uninformed Search}
\begin{enumerate}
    \item \textbf{Implementation:} Graph-based IDS. Step costs are equal, thus it is optimal~\cite[p88]{stuart_russell_artifical_2010}. Furthermore, since the search space is large and the depth of the solution is not known, IDS is preferred ~\cite[p90]{stuart_russell_artifical_2010}.
    \item \textbf{Correctness:} Branching factor \( b \leq 4 \) is finite, thus IDS is complete ~\cite[p88-90]{stuart_russell_artifical_2010}. 
    \item \textbf{Time Complexity:} \( O(b^d) \) ~\cite[p88-90]{stuart_russell_artifical_2010}.
    \item \textbf{Space Complexity:} \( O(bd) \) ~\cite[p88-90]{stuart_russell_artifical_2010}.
\end{enumerate}

\subsection{Informed Search}
\begin{enumerate}
    \item \textbf{Implementation:} Graph-based \( A^* \) search. It improves on greedy best first search (i.e. \( f(n) = h(n) \)) as it avoids expanding paths that are already expensive (i.e. \( f(n) = g(n) + h(n) \)).
    \item \textbf{Correctness:} Since the search space is finite, \( A^* \) search will be complete.
    \item \textbf{Time Complexity:} \( O(b^{h^*(s_0) - h(s_0)}) \) ~\cite[p93-99]{stuart_russell_artifical_2010}.
    \item \textbf{Space Complexity:} \( O(b^m) \) ~\cite[p93-99]{stuart_russell_artifical_2010}.
\end{enumerate}

\subsection{\(h_1:\) Manhattan Distance} 
\textbf{Justification:} Manhattan Distance (1) is consistent and (2) it dominates Euclidean Distance heuristic, thus theoretically more efficient ~\cite[104]{stuart_russell_artifical_2010}. \\
\textbf{Definition:} Manhattan Distance heuristic is defined as the sum of the horizontal distance and vertical distance from their goal positions ~\cite[p103]{stuart_russell_artifical_2010}. More formally, \( h_1(m) = D_v(m) + D_h(m) \). \\
\textbf{Proof for Consistency:} Proof in appendix \ref{appendix:manhat_cons}. \\
\textbf{Proof for Domination:} \( \forall s \in S, h_{2}(s) \leq D_h(s) + D_v(s) (\because \text{triangle inequality}) \), where S denotes the set of possible states.

\subsection{\(h_2:\) Euclidean Distance}
\textbf{Justification:} Euclidean Distance (1) is consistent and (2) it dominates Misplace Tiles heuristic, thus theoretically more efficient ~\cite[104]{stuart_russell_artifical_2010}. \\
\textbf{Definition:} Euclidean Distance heuristic is defined as the straight line distance between the tiles from their goal position ~\cite{rosalind_euclidean_nodate}. \\
\textbf{Proof for Consistency:} Prove by Construction. \\
Euclidean Distance is a form general triangle inequality, given that the Euclidean Distance from start state \( S \) to end state \( G \) (1 side of the triangle) cannot be longer than the sum of the 2 sides (the actual distance from S to middle state N and the Euclidean Distance from N to G) as the Euclidean Distance from \( S \) to \( G \) is already the shortest path. 
Since general triangle inequality fulfills the definition of consistency~\cite[p95]{stuart_russell_artifical_2010}, Euclidean Distance is consistent \( (\bullet) \). \\
\textbf{Proof for Domination:} \( \forall s \in S: h_{misplaced}(s) = 1 \implies h_{2}(s) \geq 1, h_{misplaced}(s) = 0 \implies h_{2}(s) = 0 \), where S denotes the set of possible states.

\subsection{ \(h_3: \) Linear Conflict}
\textbf{Justification:} Linear Conflict (1) is consistent and (2) it dominates Manhattan Distance heuristic, thus theoretically more efficient ~\cite[104]{stuart_russell_artifical_2010}. \\
\textbf{Definition:} Two tiles \( t_j \) and \( t_k \) are in a linear conflict if \( t_j \) and \( t_k \) are in the same line, 
the goal positions of \( t_j \) and \( t_k \) are both in that line, 
\( t_j \) is to the right of \( t_k \), and the goal position of \( t_j \) is to the left of the goal position of \( t_k \) \cite[p13]{othar_hansson_generating_1985}. \\
\textbf{Derivation.} For any state \( s \),
\begin{enumerate}
    \item For each tile \( t_j \) in \( r_i \), let \( C(t_j, r_i) \) denote the number of tiles conflicting with \( t_j \) in row \( r_i \).
    \item While there is a non-zero \( C(t_j, r_i) \) value, 
    % (a) Move out the tile with the most conflicts from \( r_i \). Let this tile be \( t_k \).
    % (b) Set \( C(t_k, r_i) \) = 0.
    % (c) For every tile \( t_j \) in conflict with \( t_k \), decrement \( C(t_j, r_i) \) by 1. 
    % (d) Let \( lc(s, r_i) \) denote the number of tiles that must be removed from row \( r_i \) in order to resolve the linear conflicts in \( r_i \). Increment \( lc(s, r_i) \) by 1.
    \begin{enumerate}
        \item Move out the tile with the most conflicts from \( r_i \). Let this tile be \( t_k \).
        \item Set \( C(t_k, r_i) \) = 0.
        \item For every tile \( t_j \) in conflict with \( t_k \), decrement \( C(t_j, r_i) \) by 1.
        \item Let \( lc(s, r_i) \) denote the number of tiles that must be removed from row \( r_i \) in order to resolve the linear conflicts in \( r_i \). Increment \( lc(s, r_i) \) by 1.
    \end{enumerate}
    \item Repeat Step 1 and 2 for other rows and columns and sum the values of all \( lc (s, r_i) \) and \( lc(s, c_i) \).
    \item Let \( LinearConflict(s) \) denote the minimum number of additional moves necessary to resolve the linear conflicts in state \( s \). \( LinearConflict(s) \) = 2 x result from Step 3.
    \[
        h_3(s) = ManhattanDistance(s) + LinearConflict(s)
    \]
\end{enumerate}
\textbf{Proof for Consistency:} Proof By Cases. \\
    To prove consistency, we must prove that for all state \( s \) and \( s' \), \( f(s') \geq f(s) \), where \( s' \) is the successor of \( s \).
\[
    f(s) = g(s) + h(s)
\]
where $g(s') = g(s) + 1$ and $h(s) = ManhattanDistance(s) + LinearConflict(s)$. \\
Assume that tile \( t_j \) moves from row \( r_i \) to row \( r_j \) and stays in the same column. Let \( ManhattanDistance(s) \) be \( MD(s) \) and \( LinearConflict(s) \) be \( LC(s) \). 
\begin{enumerate}
    \item \textbf{Case 1:} Both \( r_i \) and \( r_j \) are not the goal row of \( t_j \).
    
        \( MD(s') = MD(s) \pm 1 \). \( LC(s) \) is unchanged. Thus, \( h(s') = h(s) \pm 1 \) and \( f(s') = f(s) + 1 \pm 1 \geq f(s) \).
    
    \item \textbf{Case 2:} \( r_j \) is the goal row of \( t_j \).
        
        As \( t_j \) moves to its goal row, \( MD(s') = MD(s) - 1 \). Since \( r_i \) is not the goal row of \( t_j \), \( lc(s', r_i) = lc(s, r_i) \). 
        As \( r_j \) is the goal row, the conflicts in row \( r_j \) may or may not increase; so it is either \( lc(s', r_j) = lc(s, r_j) \) or \( lc(s', r_j) = lc(s, r_j) + 2 \). 
        Hence, \( h(s') = h(s) \pm 1 \) and \( f(s') = f(s) + 1 \pm 1 \geq f(s) \).

    \item \textbf{Case 3:} \( r_i \) is the goal row of \( t_j \).
    
        As \( t_j \) moves away from its goal row, \( MD(s') = MD(s) + 1 \). 
        As \( r_i \) is the goal row, the conflicts in row \( r_i \) may or may not decrease; so it is either \( lc(s', r_i) = lc(s, r_i) \) or \( lc(s', r_i) = lc(s, r_i) - 2 \). 
        Since \( r_j \) is not the goal row of \( t_j \), \( lc(s', r_j) = lc(s, r_j) \). 
        Therefore, \( h(s') = h(s) \pm 1 \) and \( f(s') = f(s) + 1 \pm 1 \geq f(s) \).
\end{enumerate}
All 3 cases show that \( f(s') \geq f(s) \). Thus, for any tile which moves from column \( c_i \) to \( c_j \) while remaining in the same row, \( f(s') \geq f(s) \) will still hold by the symmetry of the puzzle. \\
\textbf{Proof for Domination:} \( \forall s \in S: (h_3(s) = h_1(s) + \text{LinearConflict(s)}) \geq h_{1}(s) (\because LinearConflict(s) \geq 0) \), where S denotes the set of possible states.

\section{Experimental Setup}
\textbf{Experiment Goals:} Our experiment aims to measure (1) \textbf{time complexity}, (2) \textbf{space complexity}, and (3) \textbf{actual run time}. 
(1) shows the theoretical time efficiency in terms of the number of nodes generated. % \footnote{Measured by number of nodes generated}. 
(2) shows the maximum memory required for the search in terms of the max number of nodes stored. %\footnote{Measured by the maximum number of nodes stored in memory during the search}. 
(3) shows the real time needed for the algorithm to reach the goal state. \\ % \footnote{Measured by by the number of seconds needed by the algorithm to reach the goal state}.\\
% \textbf{Actual Time Taken} shows the amount of real time needed for the algorithm to reach the goal sate. 
% \begin{enumerate}
%     \item \textbf{Time Complexity} shows the theoretical time efficiency of the algorithm in minimising the number of nodes expanded before reaching the goal state.
%     \item \textbf{Space Complexity} shows the maximum amount of memory required while running the algorithm.
%     \item \textbf{Actual Time Taken} shows the amount of real time needed for the algorithm to reach the goal sate.
% \end{enumerate}
% \subsection{Experiment Implementation Description}
% \textbf{Time Complexity} is measured by the number of nodes generated during the search (i.e. number of the explored states) \cite[p80]{stuart_russell_artifical_2010}. \\
% \textbf{Space Complexity} is measured by the maximum number of nodes stored in memory during the search \cite[p80]{stuart_russell_artifical_2010}. This is measured by the largest summation of number of nodes in the explored set and frontier size during the search. \\
% \textbf{Actual time taken} is measured by the number of seconds needed by the algorithm to reach the goal state.
\textbf{Experiment Implementation Details:} For n = \{1 \dots 27\}
\begin{enumerate}
    \item Generate \(3 \times 3 \) matrix \( M \) that has \( n \) number of steps to reach the goal state.
    \item Perform search algorithm on matrix \( M \).
    \item Plot the number of nodes generated, maximum nodes in memory, and the actual run time.
    \item To minimise bias, for each iteration, the puzzle solves 30 different puzzles of n steps and the average number of nodes and maximum nodes in memory are taken.
\end{enumerate}
\section{Results and Discussion}
\begin{centering}
    \captionof{figure}{Performance of the 3 heuristics under 27 levels of k-puzzle difficulty.}
    \includegraphics[width=\textwidth]{Figure_1.png}
\end{centering}
In the analysis we denote the Euclidean, Manhattan, and Linear Conflicts heuristics as E, M and L respectively. \\
From the Time and Space Complexity graphs in Fig 1 above, for step values above 15, we observe that M and L outperform E. This is in line with the theoretical explanation of how M and L dominate E, accounting for the performance difference. In addition, for step values higher than 22, we observe that L outperforms M in terms of both time and space complexity. This is also in line with the theoretical explanation of how L dominates M which translates directly into time and space efficiency ~\cite[p104]{stuart_russell_artifical_2010}.\\
However in terms of actual running time, L takes longer to solve the puzzle compared to M.  This is contrary to our preliminary expectation that L will be more time efficient than M. This contradiction can be explained by the extra time required to calculate the heuristic for each node before it is put in the frontier.
% In conclusion, our experiment has shown that in general, while more dominant heuristics tend to be more efficient in terms of time and space complexity in both theory and practice, there are exceptions such as the case of M and L (actual time) as stated above which are due to the additional computational time needed to compute the heuristic.
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\pagebreak
\bibliographystyle{splncs04}
\bibliography{CS3243_project_1}

\appendix
\section{Rule to Check if k-puzzle is Solvable}
\textbf{Definition:}~\cite{princeton_computer_science_8-puzzle_nodate}. A pair of tiles form an \textit{inversion} if the values on tiles are in the reverse order of their appearance in the goal state. \\
\textbf{Rules}~\cite{princeton_computer_science_8-puzzle_nodate}. Let \( M \) denote a \( k \times k \) matrix, \( m_{i, j} \) denote a blank tile in \( M \), and \( n_i \) denote the number of inversions in the intial state \( M_{initial} \). Puzzle is solvable if (1) \( k \) is odd and \( n_i \) is even or (2) \( k \) is even, the sum of \(n_i \) and \( i \) is odd.


\appendix
\section{Proof for Manhattan Distance Consistency}
\label{appendix:manhat_cons}
\begin{proof} Proof by Cases
    \begin{enumerate}
        \item \( |h(n') - h(n) = 1| \) (\( \because c(n, a, n') = 1 \), any node n' is 1 step away from node n)
        \item Case 1: \( h(n') = h(n) + 1 \)
        \begin{enumerate}
            \item \( h(n) \leq h(n) + 1 + 1 \implies h(n) \leq h(n') + c(n, a, n') \)
        \end{enumerate}
        \item Case 2: \( h(n') = h(n) - 1 \)
        \begin{enumerate}
            \item \( h(n) \leq h(n) - 1 + 1 \implies h(n) \leq h(n') + c(n, a, n') \)
        \end{enumerate}
        \item For both cases of \( h(n') \), \( h(n) \) is consistent. (\(\bullet\))
    \end{enumerate}
\end{proof}

% \section{Proof for Euclidean Distance Consistency}
% \label{appendix:euc_cons}

% \begin{proof} Proof by Construction. \\
%     Euclidean Distance is a form of general triangle inequality, given that the Euclidean Distance from start state \( S \) to end state \( G \) (1 side of the triangle) cannot be longer than the sum of the 2 sides (the actual distance from S to middle state N and the Euclidean Distance from N to G) as the Euclidean Distance from \( S \) to \( G \) is already the shortest path. 
%     Since general triangle inequality fulfills the definition of consistency~\cite[p95]{stuart_russell_artifical_2010}, Euclidean Distance is consistent.
% \end{proof}

% \section{Proof for Linear Conflict}
% \label{appendix:linear_conflict}

% \begin{proof} Proof by Cases. \\
%     To prove consistency, we must prove that for all state \( s \) and \( s' \), \( f(s') \geq f(s) \), where \( s' \) is the successor of \( s \).
% \[
%     f(s) = g(s) + h(s)
% \]
% where $g(s') = g(s) + 1$ and $h(s) = ManhattanDistance(s) + LinearConflict(s)$. \\
% Assume that tile \( t_k \) moves from row \( r_i \) to row \( r_j \) and stays in the same column. Let \( ManhattanDistance(s) \) be \( MD(s) \) and \( LinearConflict(s) \) be \( LC(s) \). 
% \begin{enumerate}
%     \item \textbf{Condition 1:} Both \( r_i \) and \( r_j \) are not the goal row of \( t_j \).
    
%         \( MD(s') = MD(s) \pm 1 \). \( LC(s) \) is unchanged. Thus, \( h(s') = h(s) \pm 1 \) and \( f(s') = f(s) + 1 \pm 1 \geq f(s) \).
    
%     \item \textbf{Condition 2:} \( r_j \) is the goal row of \( t_j \).
        
%         As \( t_j \) moves to its goal row, \( MD(s') = MD(s) - 1 \). Since \( r_i \) is not the goal row of \( t_j \), \( lc(s', r_i) = lc(s, r_i) \). 
%         As \( r_j \) is the goal row, the conflicts in row \( r_j \) may or may not increase; so it is either \( lc(s', r_j) = lc(s, r_j) \) or \( lc(s', r_j) = lc(s, r_j) + 2 \). 
%         Hence, \( h(s') = h(s) \pm 1 \) and \( f(s') = f(s) + 1 \pm 1 \geq f(s) \).

%     \item \textbf{Condition 3:} \( r_i \) is the goal row of \( t_j \).
    
%         As \( t_j \) moves away from its goal row, \( MD(s') = MD(s) + 1 \). 
%         As \( r_i \) is the goal row, the conflicts in row \( r_i \) may or may not decrease; so it is either \( lc(s', r_i) = lc(s, r_i) \) or \( lc(s', r_i) = lc(s, r_i) - 2 \). 
%         Since \( r_j \) is not the goal row of \( t_j \), \( lc(s', r_j) = lc(s, r_j) \). 
%         Therefore, \( h(s') = h(s) \pm 1 \) and \( f(s') = f(s) + 1 \pm 1 \geq f(s) \).
% \end{enumerate}
% All 3 cases show that \( f(s') \geq f(s) \). Thus, for any tile which moves from column \( c_i \) to \( c_j \) while remaining in the same column, \( f(s') \geq f(s) \) will still hold by the symmetry of the puzzle.
% \end{proof}
\end{document}
